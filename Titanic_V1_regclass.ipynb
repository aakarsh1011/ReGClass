{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file locations\n",
    "train_fil_loc = \"D:/work data/titanic-machine learning for disaster/train.csv\"\n",
    "test_file_loc = \"D:/work data/titanic-machine learning for disaster/test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading training data \n",
    "train_data = pd.read_csv(train_fil_loc)\n",
    "test_data = pd.read_csv(test_file_loc)\n",
    "full_data = [train_data,test_data]                   #creating complete dataset to  convert them into desired format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "#general info of the data\n",
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sex       female  male\n",
      "Title                 \n",
      "Capt           0     1\n",
      "Col            0     2\n",
      "Countess       1     0\n",
      "Don            0     1\n",
      "Dr             1     6\n",
      "Jonkheer       0     1\n",
      "Lady           1     0\n",
      "Major          0     2\n",
      "Master         0    40\n",
      "Miss         182     0\n",
      "Mlle           2     0\n",
      "Mme            1     0\n",
      "Mr             0   517\n",
      "Mrs          125     0\n",
      "Ms             1     0\n",
      "Rev            0     6\n",
      "Sir            0     1\n"
     ]
    }
   ],
   "source": [
    "#let's work with the categorical values first\n",
    "#checking for patterns in titles\n",
    "import re\n",
    "\n",
    "def get_title(name):\n",
    "    title_search = re.search(' ([A-Za-z]+)\\.', name)\n",
    "    # If the title exists, extract and return it.\n",
    "    if title_search:\n",
    "        return title_search.group(1)\n",
    "    return \"\"\n",
    "\n",
    "for dataset in full_data:\n",
    "    dataset['Title'] = dataset['Name'].apply(get_title)\n",
    "\n",
    "print(pd.crosstab(train_data['Title'], train_data['Sex']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Title  Survived\n",
      "0  Master  0.575000\n",
      "1    Miss  0.702703\n",
      "2      Mr  0.156673\n",
      "3     Mrs  0.793651\n",
      "4    Rare  0.347826\n"
     ]
    }
   ],
   "source": [
    "#here we have few noise\n",
    "#mispelled words and other things\n",
    "#we will be renaming them\n",
    "\n",
    "for dataset in full_data:\n",
    "    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col',\\\n",
    "     'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "\n",
    "    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n",
    "\n",
    "print (train_data[['Title', 'Survived']].groupby(['Title'], as_index=False).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Pclass  Survived\n",
      "0       1  0.629630\n",
      "1       2  0.472826\n",
      "2       3  0.242363\n"
     ]
    }
   ],
   "source": [
    "#lets take a look at the pclass and the survival rate\n",
    "print (train_data[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean())\n",
    "       #.mean() calculates the mean of value of the attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Sex  Survived\n",
      "0  female  0.742038\n",
      "1    male  0.188908\n"
     ]
    }
   ],
   "source": [
    "#survival rate based on gender\n",
    "print(train_data[['Sex','Survived']].groupby(['Sex'],as_index = False).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Ages are : 89\n",
      "Missing values of Age in training data: 177\n"
     ]
    }
   ],
   "source": [
    "#looking at the age \n",
    "print('Unique Ages are : {}'.format(len(train_data['Age'].unique())))\n",
    "print('Missing values of Age in training data: {}'.format(train_data['Age'].isna().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacinig missing values by the mean age\n",
    "#using imputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(missing_values = np.nan, strategy = 'mean', verbose=0)\n",
    "imputer.fit(train_data.iloc[:, 5:6])\n",
    "train_data['imputer_age'] = imputer.transform(train_data.iloc[:, 5:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min value of age: 0.42\n",
      "max value of age: 80.0\n"
     ]
    }
   ],
   "source": [
    "#there are 89 unique values so am just grouping them\n",
    "print('min value of age: {}'.format(min(train_data[\"Age\"])))\n",
    "print('max value of age: {}'.format(max(train_data['Age'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets group the age into 5 catgories\n",
    "#0-16\n",
    "#17-32\n",
    "#33-48\n",
    "#48-80\n",
    "\n",
    "type(train_data['Age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting series of Age into 5 groups\n",
    "#pd.cut does uneven grouping\n",
    "train_data['Cat_age'] = pd.cut(train_data['imputer_age'],5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    (16.336, 32.252]\n",
      "1    (32.252, 48.168]\n",
      "2    (16.336, 32.252]\n",
      "3    (32.252, 48.168]\n",
      "4    (32.252, 48.168]\n",
      "Name: Cat_age, dtype: category\n",
      "Categories (5, interval[float64]): [(0.34, 16.336] < (16.336, 32.252] < (32.252, 48.168] < (48.168, 64.084] < (64.084, 80.0]]\n"
     ]
    }
   ],
   "source": [
    "print(train_data['Cat_age'][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Cat_age  Survived\n",
      "0    (0.34, 16.336]  0.550000\n",
      "1  (16.336, 32.252]  0.344168\n",
      "2  (32.252, 48.168]  0.404255\n",
      "3  (48.168, 64.084]  0.434783\n",
      "4    (64.084, 80.0]  0.090909\n"
     ]
    }
   ],
   "source": [
    "#looking at the categorized age and their mean of the survival rate\n",
    "print(train_data[['Cat_age','Survived']].groupby(['Cat_age'],as_index = False).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique prices of fare are: 248\n"
     ]
    }
   ],
   "source": [
    "#lets take a look at the fare \n",
    "print('Unique prices of fare are: {}'.format(len(train_data['Fare'].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min fare: 0.0\n",
      "max fare: 512.3292\n"
     ]
    }
   ],
   "source": [
    "#lets categorize fare into intervals too\n",
    "print('min fare: {}'.format(min(train_data['Fare'])))\n",
    "print('max fare: {}'.format(max(train_data['Fare'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Cat_fare  Survived\n",
      "0   (-0.001, 7.91]  0.197309\n",
      "1   (7.91, 14.454]  0.303571\n",
      "2   (14.454, 31.0]  0.454955\n",
      "3  (31.0, 512.329]  0.581081\n"
     ]
    }
   ],
   "source": [
    "#categorizing the fare in 4 equal  parts using pd.qcut\n",
    "train_data['Cat_fare'] = pd.qcut(train_data['Fare'],4)\n",
    "print(train_data[['Cat_fare','Survived']].groupby(['Cat_fare'], as_index = False).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values are: 2\n",
      "Unique values are: 4, which are: ['S' 'C' 'Q' nan]\n"
     ]
    }
   ],
   "source": [
    "#checking the missing values\n",
    "print('Missing values are: {}'.format(train_data['Embarked'].isna().sum()))\n",
    "type(train_data['Embarked'][0])\n",
    "print('Unique values are: {}, which are: {}'.format(len(train_data['Embarked'].unique()),train_data[\"Embarked\"].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S    644\n",
      "C    168\n",
      "Q     77\n",
      "Name: Embarked, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#checing the values counts  of Embarked\n",
    "print(train_data['Embarked'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now values counts are: S    646\n",
      "C    168\n",
      "Q     77\n",
      "Name: Embarked, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#most of the data is 'S', so we can replace 'nan' with 'S'\n",
    "train_data['Embarked'] = train_data['Embarked'].fillna('S')\n",
    "print('Now values counts are: {}'.format(train_data['Embarked'].value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Embarked  Survived\n",
      "0        C  0.553571\n",
      "1        Q  0.389610\n",
      "2        S  0.339009\n"
     ]
    }
   ],
   "source": [
    "#checking embarked against survival rate\n",
    "print(train_data[['Embarked','Survived']].groupby(['Embarked'],as_index = False).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
       "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked', 'Title', 'mean_Age',\n",
       "       'imputer_age', 'Cat_age', 'Cat_fare'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique values are: 7\n",
      "which are: [1 0 3 4 2 5 8]\n",
      "Missing values are: 0\n"
     ]
    }
   ],
   "source": [
    "#let's take a look at SibSp\n",
    "print('Total unique values are: {}'.format(len(train_data['SibSp'].unique())))\n",
    "print('which are: {}'.format(train_data['SibSp'].unique()))\n",
    "print('Missing values are: {}'.format(train_data['SibSp'].isna().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SibSp  Survived\n",
      "0      0  0.345395\n",
      "1      1  0.535885\n",
      "2      2  0.464286\n",
      "3      3  0.250000\n",
      "4      4  0.166667\n",
      "5      5  0.000000\n",
      "6      8  0.000000\n"
     ]
    }
   ],
   "source": [
    "#let's check it against survival rate\n",
    "print(train_data[['SibSp','Survived']].groupby(['SibSp'], as_index = False).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique values are: 7\n",
      "which are: [0 1 2 5 3 4 6]\n",
      "Missing values are: 0\n"
     ]
    }
   ],
   "source": [
    "#let's take a look at Parch\n",
    "print('Total unique values are: {}'.format(len(train_data['Parch'].unique())))\n",
    "print('which are: {}'.format(train_data['Parch'].unique()))\n",
    "print('Missing values are: {}'.format(train_data['Parch'].isna().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Parch  Survived\n",
      "0      0  0.343658\n",
      "1      1  0.550847\n",
      "2      2  0.500000\n",
      "3      3  0.600000\n",
      "4      4  0.000000\n",
      "5      5  0.200000\n",
      "6      6  0.000000\n"
     ]
    }
   ],
   "source": [
    "#let's check it against survival rate\n",
    "print(train_data[['Parch','Survived']].groupby(['Parch'], as_index = False).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size: 891\n",
      "Missing values are: 687\n"
     ]
    }
   ],
   "source": [
    "#let's take a look at Cabin\n",
    "print('Total size: {}'.format(len(train_data['Cabin'])))\n",
    "print('Missing values are: {}'.format(train_data['Cabin'].isna().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#most of the data is missing from the cabin hence it's of no use\n",
    "train_data = train_data.drop(columns='Cabin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique values are: 681\n",
      "Missing values are: 0\n"
     ]
    }
   ],
   "source": [
    "#let's take a look at Ticket\n",
    "print('Total unique values are: {}'.format(len(train_data['Ticket'].unique())))\n",
    "print('Missing values are: {}'.format(train_data['Ticket'].isna().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ticket is not useful either as it contain very different type of values\n",
    "train_data = train_data.drop(columns='Ticket')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
       "       'Parch', 'Fare', 'Embarked', 'Title', 'imputer_age', 'Cat_age',\n",
       "       'Cat_fare'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#passengerID is of no use either \n",
    "#we already have inmputer age and mean age so we can drop age too\n",
    "#we don't need fare anymore as we have converted it into category\n",
    "#We have Tittle so we don't need the name anymore \n",
    "rem = ['PassengerId','Age','Fare','Name']\n",
    "#creating a new dataset\n",
    "X = train_data.drop(columns=rem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 10 columns):\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Sex            891 non-null object\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Embarked       891 non-null object\n",
      "Title          891 non-null object\n",
      "imputer_age    891 non-null float64\n",
      "Cat_age        891 non-null category\n",
      "Cat_fare       891 non-null category\n",
      "dtypes: category(2), float64(1), int64(4), object(3)\n",
      "memory usage: 58.0+ KB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas._libs.interval.Interval'>\n",
      "<class 'pandas._libs.interval.Interval'>\n"
     ]
    }
   ],
   "source": [
    "#now we need to convert all the categorical data into numercial value through encoding\n",
    "print(type(train_data['Cat_age'][0]))    #values of 'Cat_age' is of interval datatype\n",
    "print(type(train_data['Cat_fare'][0]))   #values of 'Cat_fare' is of interval datatype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to encode these intervals and give them a numeric value so we can use it in our Ml algorithms"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
